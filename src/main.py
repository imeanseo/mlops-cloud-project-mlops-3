# src/main.py (ì›ë³¸ ìœ ì§€ + ìƒˆ ê¸°ëŠ¥ ì¶”ê°€)

import os
import sys
from datetime import datetime

# sys.path ê²½ë¡œ ì„¤ì •
sys.path.append(
    os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
)

import fire
from dotenv import load_dotenv
import wandb

from src.utils.utils import project_path, auto_increment_run_suffix, upload_model_to_s3, upload_file_to_s3
from src.dataset.games_log import load_games_log
from src.dataset.data_loader import create_user_item_matrix, train_val_split
from src.train.train import train_model
from src.inference.inference import ItemCFInference, run_inference


# ë™ì ìœ¼ë¡œ ê²½ë¡œ ê³„ì‚° (ë°°ì¹˜ ì¶”ë¡ ìš©)
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
MLOPS_DIR = os.path.dirname(SCRIPT_DIR)
OPT_DIR = os.path.dirname(MLOPS_DIR)
DEFAULT_GAME_INFO_PATH = os.path.join(OPT_DIR, 'data-prepare', 'result', 'popular_games.csv')


def get_runs(project_name):
    """WandB runs ê°€ì ¸ì˜¤ê¸°"""
    try:
        api = wandb.Api()
        entity = api.default_entity

        if entity:
            return api.runs(f"{entity}/{project_name}", order="-created_at")
        else:
            return api.runs(project_name, order="-created_at")

    except Exception as e:
        print(f"Error fetching runs: {e}")
        return []


def get_latest_run(project_name):
    """ìµœì‹  run ì´ë¦„ ê°€ì ¸ì˜¤ê¸°"""
    try:
        runs = get_runs(project_name)
        runs_list = list(runs)

        if not runs_list:
            return None

        import re
        for run in runs_list:
            if re.search(r'-\d+$', run.name):
                return run.name

        return None

    except Exception as e:
        print(f"Error: {e}")
        return None


def main():
    """
    ëª¨ë¸ í•™ìŠµ (ê¸°ì¡´ ë¡œì§)
    """
    # 1. WandB API Key
    load_dotenv(os.path.join(project_path(), ".env"))
    wandb_api_key = os.getenv("WANDB_API_KEY")
    if wandb_api_key is None:
        raise ValueError("WANDB_API_KEYê°€ .env íŒŒì¼ì— ì—†ìŠµë‹ˆë‹¤.")
    wandb.login(key=wandb_api_key)

    # 2. ë°ì´í„° ë¡œë“œ
    df = load_games_log("games_log.csv")

    # 3. ìœ ì €-ì•„ì´í…œ í–‰ë ¬ ìƒì„±
    user_item_matrix = create_user_item_matrix(df)

    # 4. Train/Validation ë¶„í• 
    train_matrix, val_matrix = train_val_split(user_item_matrix, val_ratio=0.2, seed=42)

    # 5. WandB run ì´ë¦„ ìƒì„±
    project_name = "game_item_cf_recommendation"

    try:
        latest_run = get_latest_run(project_name)
        print(f"Latest run found: {latest_run}")

        if latest_run:
            desired_run_name = auto_increment_run_suffix(latest_run)
            if desired_run_name:
                print(f"Incremented to: {desired_run_name}")
            else:
                print("Failed to increment, using default")
                desired_run_name = f"{project_name}-001"
        else:
            print("No previous runs found, using default")
            desired_run_name = f"{project_name}-001"

    except Exception as e:
        print(f"Error getting run name: {e}")
        desired_run_name = f"{project_name}-001"

    print(f"Final run name: {desired_run_name}")

    # 6. WandB ì´ˆê¸°í™”
    wandb.init(
        project=project_name,
        name=desired_run_name,
        notes="item-based CF recommendation model",
        tags=["itemCF", "recommendation", "games"],
        config={"n_epochs": 10}
    )

    # 7. ëª¨ë¸ í•™ìŠµ
    model, recall_history = train_model(
        train_matrix,
        val_matrix,
        n_epochs=10,
        project_name=project_name
    )

    # 8. íŠ¹ì • ìœ ì € ì¶”ì²œ (í…ŒìŠ¤íŠ¸)
    target_user = 10
    recommended_games = model.recommend(target_user, train_matrix, top_k=5)
    print(f"\nUser {target_user} ì¶”ì²œ ê²°ê³¼:")
    print(recommended_games)

    # 9. WandB ë¡œê·¸
    wandb.log({"final_recall": recall_history[-1]})
    wandb.finish()

    return model, recall_history


def train():
    """
    í•™ìŠµ + S3 ì—…ë¡œë“œ (CLI ëª…ë ¹)
    """
    print("ğŸš€ Starting training pipeline...")

    # í•™ìŠµ
    model, recall_history = main()
    print("âœ… Training completed")

    # S3 ì—…ë¡œë“œ
    bucket_name = os.getenv('S3_BUCKET_NAME')
    if bucket_name:
        upload_model_to_s3('itemCF', bucket_name, model_type="itemCF")
        print("ğŸ‰ Model uploaded to S3!")
    else:
        print("âš ï¸ S3_BUCKET_NAME not set, skipping upload")

    return model, recall_history


def recommend(user_id: int, top_k: int = 5):
    """
    ë‹¨ì¼ ì‚¬ìš©ì ì¶”ë¡  (CLI ëª…ë ¹)
    """
    model_name = "itemCF"
    recommender = ItemCFInference(model_name=model_name)
    games = recommender.recommend(user_id, top_k)
    print(f"user_id={user_id} ì¶”ì²œ ê²°ê³¼: {games}")
    return games


def batch_inference(start_user_id: int = 1, end_user_id: int = 100, top_k: int = 12):
    """
    ë°°ì¹˜ ì¶”ë¡  (CLI ëª…ë ¹)
    ë‚˜ì¤‘ì— inference.pyì— êµ¬í˜„ í›„ ì—°ê²°
    """
    print("âš ï¸ batch_inference êµ¬í˜„ ì¤‘...")
    # TODO: inference.pyì˜ batch_inference_pipeline() í˜¸ì¶œ
    pass


# ============================================
# ìƒˆë¡œ ì¶”ê°€: S3 ê¸°ë°˜ ë°°ì¹˜ ì¶”ë¡ 
# ============================================

def recommend_all(s3_bucket: str, model_name: str = 'itemCF', 
                  game_info_path: str = None, output_dir: str = './outputs',
                  s3_prefix: str = 'inference_results'):
    """
    ìœ ì € 1-100ë²ˆ ì¶”ë¡  + S3 ì—…ë¡œë“œ (ìƒˆ ê¸°ëŠ¥)
    """
    if game_info_path is None:
        game_info_path = DEFAULT_GAME_INFO_PATH
    
    print("\n" + "=" * 60)
    print("ğŸ® RECOMMEND ALL - ìœ ì € 1-100ë²ˆ ê²Œì„ ì¶”ì²œ")
    print("=" * 60)
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    output_filename = f"user_recommendations_1-100_{timestamp}.csv"
    output_path = os.path.join(output_dir, output_filename)
    
    # ì¶”ë¡  ì‹¤í–‰
    result_path = run_inference(
        bucket_name=s3_bucket,
        model_name=model_name,
        game_info_path=game_info_path,
        start_user=1,
        end_user=100,
        top_k=5,
        output_path=output_path
    )
    
    # S3 ì—…ë¡œë“œ
    print("\n" + "=" * 60)
    print("ğŸ“¤ S3 ì—…ë¡œë“œ ì‹œì‘")
    print("=" * 60)
    s3_key = f"{s3_prefix}/{output_filename}"
    s3_path = upload_file_to_s3(result_path, s3_bucket, s3_key)
    
    print("\n" + "=" * 60)
    print("âœ… ì „ì²´ ì‘ì—… ì™„ë£Œ!")
    print("=" * 60)
    print(f"   ë¡œì»¬ íŒŒì¼: {result_path}")
    print(f"   S3 ê²½ë¡œ: {s3_path}")
    print("=" * 60 + "\n")


def upload_model(s3_bucket: str, model_name: str = 'itemCF'):
    """
    ë¡œì»¬ ëª¨ë¸ì„ S3ì— ì—…ë¡œë“œ (ìƒˆ ê¸°ëŠ¥)
    """
    print("\n" + "=" * 60)
    print("ğŸ“¤ ëª¨ë¸ S3 ì—…ë¡œë“œ")
    print("=" * 60)
    
    s3_key = upload_model_to_s3(model_name, s3_bucket, "itemCF")
    
    print("\n" + "=" * 60)
    print("âœ… ëª¨ë¸ ì—…ë¡œë“œ ì™„ë£Œ!")
    print("=" * 60)
    print(f"   S3 ê²½ë¡œ: s3://{s3_bucket}/{s3_key}")
    print("=" * 60 + "\n")


# ============================================
# Main ì‹¤í–‰
# ============================================
if __name__ == "__main__":
    fire.Fire({
        "train": train,
        "recommend": recommend,
        "batch_inference": batch_inference,
        "recommend_all": recommend_all,  # ìƒˆë¡œ ì¶”ê°€
        "upload_model": upload_model      # ìƒˆë¡œ ì¶”ê°€
    })

